---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

My name is **Yixin (Elaine) Wan** and I am a PhD student in Computer Science at UCLA. I am fortunate to be advised by Professor [**Kai-Wei Chang**](https://web.cs.ucla.edu/~kwchang/) and have been a proud member of the [UCLANLP](https://web.cs.ucla.edu/~kwchang/members/) research group. My research focuses on building trustworthy multimodal generative models: specirically, I have worked on improving the controllability, fairness, and factuality in text, image and video generation.
I completed my B.S. in Applied Mathematics (double major in Economics) also at UCLA. Go Bruins! 

Currently, I am a research intern at **Tencent AI Lab** in Bellevue, WA, working on controllable video generation. My mentor is Wenhao Yu and Lei Ke. Previously, I have interned at *Amazon AGI* and *Microsoft Research Asia (MSRA)*.  

News
======
* [2025/08] 3 papers on *LLM Unlearning* and *Fairness* accepted to **EMNLP 2025 Findings** ðŸŽ‰! Check them out:
  * [Not Every Token Needs Forgetting: Selective Unlearning to Limit Change in Utility in Large Language Model Unlearning](https://arxiv.org/abs/2506.00876)
  * [LUME: LLM Unlearning with Multitask Evaluations](https://arxiv.org/abs/2502.15097)
  * [Fact-or-Fair: A Checklist for Behavioral Testing of AI Models on Fairness-Related Queries](https://arxiv.org/abs/2502.05849)
* [2025/06] Started my internship at **Tencent AI Lab** (Bellevue)!
* [2025/05] 2 long papers on *Fairness* accepted to **ACL 2025 Main** ðŸŽ‰! Check them out:
  * [The Male CEO and the Female Assistant: Evaluation and Mitigation of Gender Biases in Text-To-Image Generation of Dual Subjects](https://arxiv.org/abs/2402.11089)
  * [White Men Lead, Black Women Help? Benchmarking and Mitigating Language Agency Social Biases in LLMs](https://arxiv.org/abs/2404.10508)
* [2025/05] Arrived at Albuquerque! I am serving as the Program Chair at **NAACL 2025's Trustworthy NLP (TrustNLP) Workshop**.
  * I am also presenting my recent work on *LLM unlearning* with **Amazon**: [Not Every Token Needs Forgetting: Selective Unlearning to Limit Change in Utility in Large Language Model Unlearning](https://arxiv.org/abs/2506.00876)