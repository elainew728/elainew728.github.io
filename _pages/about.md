---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

My name is **Yixin (Elaine) Wan** and I am a PhD student in Computer Science at UCLA. I am fortunate to be advised by Professor [**Kai-Wei Chang**](https://web.cs.ucla.edu/~kwchang/) and have been a proud member of the [UCLANLP](https://web.cs.ucla.edu/~kwchang/members/) research group. My research focuses on building trustworthy multimodal generative models: specifically, I have worked on improving the controllability, fairness, and factuality in text and image generation. I completed my B.S. in Applied Mathematics (double major in Economics) also at UCLA. Go Bruins! 

Currently, I am a research intern at **Tencent AI Lab** in Bellevue, WA, working on controllable image editing. My mentor is [Lei Ke](https://www.kelei.site/) and [Wenhao Yu](https://wyu97.github.io/). Previously, I have interned at *Amazon AGI* and *Microsoft Research Asia (MSRA)*.  

News
======
* [2025/12] üì¢ ‚≠êÔ∏è New Work on **Motion Image Editing** with *Tencent AI Lab* released! Check it out: [MotionEdit: Benchmarking and Learning Motion-Centric Image Editing](https://arxiv.org/abs/2512.10284) . Also check out more demos on our [Project Page](https://motion-edit.github.io/)!
* [2025/09] I am humbled to be awarded the 2025 [Amazon AI Fellowship](https://samueli.ucla.edu/15-ucla-engineering-doctoral-students-named-amazon-ai-fellows/) üéâ!
* [2025/08] 3 papers on *LLM Unlearning* and *Fairness* accepted to **EMNLP 2025 Findings** üéâ! Check them out:
  * [Not Every Token Needs Forgetting: Selective Unlearning to Limit Change in Utility in Large Language Model Unlearning](https://arxiv.org/abs/2506.00876)
  * [LUME: LLM Unlearning with Multitask Evaluations](https://arxiv.org/abs/2502.15097)
  * [Fact-or-Fair: A Checklist for Behavioral Testing of AI Models on Fairness-Related Queries](https://arxiv.org/abs/2502.05849)
* [2025/06] Started my internship at **Tencent AI Lab** (Bellevue)!
* [2025/05] 2 long papers on *Fairness* accepted to **ACL 2025 Main** üéâ! Check them out:
  * [The Male CEO and the Female Assistant: Evaluation and Mitigation of Gender Biases in Text-To-Image Generation of Dual Subjects](https://arxiv.org/abs/2402.11089)
  * [White Men Lead, Black Women Help? Benchmarking and Mitigating Language Agency Social Biases in LLMs](https://arxiv.org/abs/2404.10508)
* [2025/05] Arrived at Albuquerque! I am serving as the Program Chair at **NAACL 2025's Trustworthy NLP (TrustNLP) Workshop**.
  * I am also presenting my recent work on *LLM unlearning* with **Amazon**: [Not Every Token Needs Forgetting: Selective Unlearning to Limit Change in Utility in Large Language Model Unlearning](https://arxiv.org/abs/2506.00876)